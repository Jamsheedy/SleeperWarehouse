{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e08b657-62c1-4fd6-b7b0-0d3d35f81ed5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.table('sleeper.bronze_players')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c621a971-3c8a-45ed-8532-a704bd4d6ac3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8502acee-bc8a-4f91-9064-c5ccc6488a10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT * FROM sleeper.bronze_rosters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90b17c74-99c2-4d26-85a1-9ccec1ec7aa0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, expr, explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd81b298-ba4e-42f2-bdd7-cf614d87742f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.table(\"sleeper.bronze_rosters\") \\\n",
    "    .withColumn(\"player_id\", explode(\"players\")) \\\n",
    "    .withColumn(\"is_starter\", expr(\"array_contains(starters, player_id)\")) \\\n",
    "    .withColumn(\"player_nickname\", expr(\"metadata['p_nick_' || player_id]\"))\n",
    "\n",
    "df = df.select(\"owner_id\", \"roster_id\", \"player_id\", \"is_starter\", \"player_nickname\", \"_league_id\", \"_matchup_week\", \"_year\", \"_ingested_ts\")\\\n",
    "    .withColumn(\"_snapshot_ts\", current_timestamp())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f3a658d-7164-4177-93bc-ffd77d4b500f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT * FROM sleeper.bronze_rosters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f22f7a31-3504-4ea4-84b5-f5b99ce1644d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.table(\"sleeper.bronze_rosters\") \\\n",
    "    .withColumn(\"streak\", expr(\"metadata['streak']\")) \\\n",
    "    .withColumn(\"record\", expr(\"metadata['record']\"))\\\n",
    "    .withColumn(\"wins\", expr(\"settings['wins']\"))\\\n",
    "    .withColumn(\"losses\", expr(\"settings['losses']\"))\\\n",
    "    .withColumn(\"ties\", expr(\"settings['ties']\"))\\\n",
    "    .withColumn(\"fpts\", expr(\"settings['fpts'] + settings['fpts_decimal'] / 100\")) \\\n",
    "    .withColumn(\"fpts_against\", expr(\"settings['fpts_against'] + settings['fpts_against_decimal'] / 100\")) \\\n",
    "    .withColumn(\"total_moves\", expr(\"settings['total_moves']\")) \\\n",
    "    .withColumn(\"waiver_budget_used\", expr(\"settings['waiver_budget_used']\")) \\\n",
    "    .withColumn(\"waiver_position\", expr(\"settings['waiver_position']\"))\n",
    "\n",
    "df = df.select(\n",
    "    \"owner_id\", \n",
    "    \"roster_id\",\n",
    "    \"streak\",\n",
    "    \"record\",\n",
    "    \"wins\",\n",
    "    \"losses\",\n",
    "    \"ties\",\n",
    "    \"fpts\",\n",
    "    \"fpts_against\",\n",
    "    \"total_moves\",\n",
    "    \"waiver_budget_used\",\n",
    "    \"waiver_position\",\n",
    "    \"_league_id\",\n",
    "    \"_matchup_week\",\n",
    "    \"_year\",\n",
    "    \"_ingested_ts\",\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01c6a633-edd9-4b6e-a249-eb2b83a85bfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT * FROM sleeper.bronze_matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c474c9b7-26d3-4173-9710-55cf2f0c5b39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.table('sleeper.bronze_matchups')\\\n",
    "    .select(\n",
    "        \"matchup_id\",\n",
    "        \"roster_id\",\n",
    "        \"points\",\n",
    "        \"_league_id\",\n",
    "        \"_matchup_week\",\n",
    "        \"_year\",\n",
    "        \"_ingested_ts\"\n",
    "    ).withColumn(\"_snapshot_ts\", current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "793c8a3e-7813-412d-b0bf-51e58c212e3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT * FROM sleeper.bronze_matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ef5da31-1265-4d2d-b392-d55b9cd1c54e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains, col, explode\n",
    "\n",
    "df = spark.read.table('sleeper.bronze_matchups') \\\n",
    "    .withColumn(\"player_id\", explode(col(\"players\"))) \\\n",
    "    .withColumn(\"is_starter\", array_contains(col(\"starters\"), col(\"player_id\"))) \\\n",
    "    .withColumn(\"player_points\", col(\"players_points\")[col(\"player_id\")])\n",
    "\n",
    "df = df.select(\n",
    "    \"roster_id\",\n",
    "    \"matchup_id\",\n",
    "    \"player_id\",\n",
    "    \"player_points\",\n",
    "    \"is_starter\",\n",
    "    \"_league_id\",\n",
    "    \"_matchup_week\",\n",
    "    \"_year\",\n",
    "    \"_ingested_ts\",\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf88dc83-450b-483f-89ca-61ddbba8383c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT * FROM sleeper.bronze_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "670a9d6c-0e28-4473-8ba8-2b88d168fc05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.table('sleeper.bronze_users')\\\n",
    "    .withColumnRenamed(\"display_name\", \"owner_name\")\\\n",
    "    .withColumnRenamed(\"user_id\", \"owner_id\")\\\n",
    "    .withColumnRenamed(\"is_owner\", \"is_commissioner\")\\\n",
    "    .withColumn(\"team_name\", col(\"metadata.team_name\"))\n",
    "\n",
    "df = df.select(\n",
    "    \"owner_id\",\n",
    "    \"owner_name\",\n",
    "    \"is_bot\",\n",
    "    \"is_commissioner\",\n",
    "    \"team_name\",\n",
    "    \"_league_id\",\n",
    "    \"_matchup_week\",\n",
    "    \"_year\",\n",
    "    \"_ingested_ts\"\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57a9dfa2-0749-4e7e-87c6-37f67079f573",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT * FROM sleeper.silver_matchups_players_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd213ec4-4bc4-43dd-bcb9-1a75cf400629",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat_ws, coalesce, when\n",
    "\n",
    "df_matchups_players_dim = spark.read.table('sleeper.silver_matchups_players_dim')\n",
    "df_players_dim = spark.read.table('sleeper.silver_players_dim')\n",
    "\n",
    "df_players_dim = df_players_dim.select(\n",
    "    \"player_id\",\n",
    "    \"_league_id\",\n",
    "    \"_matchup_week\",\n",
    "    coalesce(col(\"full_name\"), col(\"last_name\")).alias(\"player_name\"),\n",
    "    col(\"position\").alias(\"player_position\"),\n",
    "    col(\"team\").alias(\"nfl_team\"),\n",
    "    \"years_exp\",\n",
    "    \"injury_status\",\n",
    "    concat_ws(\" \", col(\"injury_body_part\"), col(\"injury_notes\")).alias(\"injury_notes\"),\n",
    "    \"college\",\n",
    "    when(col(\"years_exp\") == 1, True).otherwise(False).alias(\"is_rookie\")\n",
    ")\n",
    "\n",
    "df_joined = df_matchups_players_dim.join(\n",
    "    df_players_dim,\n",
    "    (df_matchups_players_dim.player_id == df_players_dim.player_id) &\n",
    "    (df_matchups_players_dim._league_id == df_players_dim._league_id) &\n",
    "    (df_matchups_players_dim._matchup_week == df_players_dim._matchup_week)\n",
    ").select(\n",
    "    \"roster_id\",\n",
    "    \"matchup_id\",\n",
    "    df_matchups_players_dim.player_id,\n",
    "    \"player_name\",\n",
    "    \"player_position\",\n",
    "    \"nfl_team\",\n",
    "    \"player_points\",\n",
    "    \"is_starter\",\n",
    "    \"years_exp\",\n",
    "    \"is_rookie\",\n",
    "    \"injury_status\",\n",
    "    \"injury_notes\",\n",
    "    \"college\",\n",
    "    df_matchups_players_dim._league_id,\n",
    "    df_matchups_players_dim._matchup_week,\n",
    "    df_matchups_players_dim._year\n",
    ")\n",
    "\n",
    "display(df_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72b1f9af-3c7d-42b1-87ba-bb17167d00cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT * FROM sleeper.silver_matchups_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc6c2af0-5a03-4df0-8244-2106d3748504",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_matchups_fact = spark.read.table('sleeper.silver_matchups_fact')\n",
    "df_rosters_dim = spark.read.table('sleeper.silver_rosters_dim')\n",
    "df_users_dim = spark.read.table('sleeper.silver_users_dim')\n",
    "\n",
    "df_result = df_matchups_fact.join(\n",
    "    df_rosters_dim,\n",
    "    (df_matchups_fact._league_id == df_rosters_dim._league_id) &\n",
    "    (df_matchups_fact.roster_id == df_rosters_dim.roster_id) &\n",
    "    (df_matchups_fact._matchup_week == df_rosters_dim._matchup_week)\n",
    ").join(\n",
    "    df_users_dim,\n",
    "    (df_matchups_fact._league_id == df_users_dim._league_id) &\n",
    "    (df_rosters_dim.owner_id == df_users_dim.owner_id) &\n",
    "    (df_matchups_fact._matchup_week == df_users_dim._matchup_week)\n",
    ").select(\n",
    "    \"matchup_id\",\n",
    "    df_matchups_fact.roster_id,\n",
    "    df_users_dim.owner_id,\n",
    "    df_users_dim.owner_name,\n",
    "    df_users_dim.is_commissioner,\n",
    "    df_users_dim.team_name,\n",
    "    df_matchups_fact.points,\n",
    "    df_rosters_dim.streak,\n",
    "    df_rosters_dim.record,\n",
    "    df_rosters_dim.wins,\n",
    "    df_rosters_dim.losses,\n",
    "    df_rosters_dim.ties,\n",
    "    df_rosters_dim.fpts,\n",
    "    df_rosters_dim.fpts_against,\n",
    "    df_rosters_dim.waiver_budget_used,\n",
    "    df_rosters_dim.waiver_position,\n",
    "    df_matchups_fact._league_id,\n",
    "    df_matchups_fact._matchup_week,\n",
    "    df_matchups_fact._year\n",
    ")\n",
    "\n",
    "display(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0028c222-c143-4d7b-bbf7-db73d2a25b32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT * FROM sleeper.silver_model_roster_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1069416-7396-4999-8557-d81f4324b00a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT * FROM sleeper.silver_model_player_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "088da45f-6b2e-4dd5-b8c3-278648fa1d31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_roster_results = spark.read.table('sleeper.silver_model_roster_results')\n",
    "df_player_performances = spark.read.table('sleeper.silver_model_player_performances')\n",
    "\n",
    "df_joined_results = df_roster_results.join(\n",
    "    df_player_performances,\n",
    "    (df_roster_results.roster_id == df_player_performances.roster_id) &\n",
    "    (df_roster_results.matchup_id == df_player_performances.matchup_id) &\n",
    "    (df_roster_results._matchup_week == df_player_performances._matchup_week)\n",
    ")\n",
    "\n",
    "df_joined_results.printSchema()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5782151327188749,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "develop_models",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
